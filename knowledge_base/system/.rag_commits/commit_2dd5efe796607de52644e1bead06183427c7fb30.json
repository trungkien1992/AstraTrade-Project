{
  "what_changed": " Implement Initial Code-Aware Chunker",
  "code_changes": "diff --git a/knowledge_base/backend/code_aware_chunker.py b/knowledge_base/backend/code_aware_chunker.py\nindex b25bbe8..1f78d90 100644\n--- a/knowledge_base/backend/code_aware_chunker.py\n+++ b/knowledge_base/backend/code_aware_chunker.py\n@@ -12,0 +13 @@ import json\n+import logging\n@@ -15,0 +17,2 @@ from enum import Enum\n+logger = logging.getLogger(__name__)\n+\n@@ -121 +124 @@ class CodeAwareChunker:\n-        \"\"\"Python-specific intelligent chunking\"\"\"\n+        \"\"\"Python-specific intelligent chunking using AST\"\"\"\n@@ -164 +167 @@ class CodeAwareChunker:\n-            # Extract classes with their methods\n+            # Extract classes with their methods (complete class definitions)\n@@ -170,8 +173,7 @@ class CodeAwareChunker:\n-                \n-                # Extract standalone functions\n-                elif isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n-                    # Check if function is not inside a class\n-                    if not self._is_method(node, tree):\n-                        func_chunk = self._extract_python_function(node, lines, file_path)\n-                        if func_chunk:\n-                            chunks.append(func_chunk)\n+            \n+            # Extract standalone functions (not inside classes)\n+            for node in tree.body:  # Only top-level nodes\n+                if isinstance(node, (ast.FunctionDef, ast.AsyncFunctionDef)):\n+                    func_chunk = self._extract_python_function(node, lines, file_path)\n+                    if func_chunk:\n+                        chunks.append(func_chunk)\n@@ -179 +181 @@ class CodeAwareChunker:\n-        except SyntaxError:\n+        except SyntaxError as e:\n@@ -180,0 +183 @@ class CodeAwareChunker:\n+            logger.warning(f\"Python AST parsing failed for {file_path}: {e}\")\n@@ -471 +474 @@ class CodeAwareChunker:\n-        \"\"\"Markdown-specific intelligent chunking by sections\"\"\"\n+        \"\"\"Markdown-specific intelligent chunking by headers using regex\"\"\"\n@@ -475 +478 @@ class CodeAwareChunker:\n-        # Split by headers\n+        # Split by headers (both # and underline styles)\n@@ -478,0 +482 @@ class CodeAwareChunker:\n+        section_start_line = 1\n@@ -481 +485,2 @@ class CodeAwareChunker:\n-            header_match = re.match(r'^(#+)\\s+(.+)$', line.strip())\n+            # Check for ATX headers (# ## ###)\n+            header_match = re.match(r'^(#{1,6})\\s+(.+)$', line.strip())\n@@ -483 +488,10 @@ class CodeAwareChunker:\n-            if header_match:\n+            # Check for Setext headers (underlined with = or -)\n+            setext_match = None\n+            if i > 0 and not header_match:\n+                prev_line = lines[i-1].strip()\n+                if prev_line and re.match(r'^=+$', line.strip()):\n+                    setext_match = (1, prev_line)  # H1 equivalent\n+                elif prev_line and re.match(r'^-+$', line.strip()):\n+                    setext_match = (2, prev_line)  # H2 equivalent\n+            \n+            if header_match or setext_match:\n@@ -498 +512 @@ class CodeAwareChunker:\n-                            start_line=max(1, i - len(current_section)),\n+                            start_line=section_start_line,\n@@ -502 +516 @@ class CodeAwareChunker:\n-                            importance='medium'\n+                            importance=self._get_header_importance(header_level)\n@@ -506,3 +520,11 @@ class CodeAwareChunker:\n-                header_level = len(header_match.group(1))\n-                current_header = header_match.group(2)\n-                current_section = [line]\n+                if header_match:\n+                    header_level = len(header_match.group(1))\n+                    current_header = header_match.group(2)\n+                    current_section = [line]\n+                else:  # setext_match\n+                    header_level = setext_match[0]\n+                    current_header = setext_match[1]\n+                    # Include the previous line and underline\n+                    current_section = [lines[i-1], line]\n+                \n+                section_start_line = i + 1\n@@ -526 +548 @@ class CodeAwareChunker:\n-                    start_line=len(lines) - len(current_section),\n+                    start_line=section_start_line,\n@@ -530 +552 @@ class CodeAwareChunker:\n-                    importance='medium'\n+                    importance=self._get_header_importance(header_level)\n@@ -532,0 +555,19 @@ class CodeAwareChunker:\n+        # If no headers found, check for content and create a single chunk\n+        if not chunks and content.strip():\n+            chunks.append(CodeChunk(\n+                content=content,\n+                metadata={\n+                    'file_path': file_path,\n+                    'language': 'markdown',\n+                    'section_title': 'Content',\n+                    'header_level': 0,\n+                    'type': 'content',\n+                    'description': 'Markdown content without headers'\n+                },\n+                start_line=1,\n+                end_line=len(lines),\n+                chunk_type=ChunkType.DOCUMENTATION,\n+                language='markdown',\n+                importance='medium'\n+            ))\n+        \n@@ -534,0 +576,11 @@ class CodeAwareChunker:\n+    def _get_header_importance(self, header_level: int) -> str:\n+        \"\"\"Determine importance based on header level\"\"\"\n+        if header_level == 1:\n+            return 'high'\n+        elif header_level == 2:\n+            return 'high'\n+        elif header_level == 3:\n+            return 'medium'\n+        else:\n+            return 'low'\n+    \ndiff --git a/knowledge_base/backend/models.py b/knowledge_base/backend/models.py\nindex df4aeb1..9e052e7 100644\n--- a/knowledge_base/backend/models.py\n+++ b/knowledge_base/backend/models.py\n@@ -45 +45,2 @@ class ProcessedDocument:\n-    source_url: Optional[str] = None\n\\ No newline at end of file\n+    source_url: Optional[str] = None\n+    file_path: Optional[str] = None\n\\ No newline at end of file\ndiff --git a/knowledge_base/backend/rag_system.py b/knowledge_base/backend/rag_system.py\nindex caaff9b..bce2ab1 100644\n--- a/knowledge_base/backend/rag_system.py\n+++ b/knowledge_base/backend/rag_system.py\n@@ -434 +434,66 @@ class AstraTradeRAG:\n-        \"\"\"Chunk a document into smaller pieces\"\"\"\n+        \"\"\"Chunk a document into smaller pieces using code-aware chunking\"\"\"\n+        chunked_docs = []\n+        \n+        # Check if code-aware chunking is enabled and we have a file path\n+        if (RAG_CONFIG.get('code_aware_chunking', False) and \n+            hasattr(doc, 'file_path') and doc.file_path):\n+            \n+            # Use CodeAwareChunker for supported file types\n+            try:\n+                from code_aware_chunker import CodeAwareChunker\n+                code_chunker = CodeAwareChunker(RAG_CONFIG)\n+                code_chunks = code_chunker.chunk_file(doc.file_path, doc.content)\n+                \n+                # Convert CodeChunk objects to our format\n+                for i, code_chunk in enumerate(code_chunks):\n+                    chunk_id = f\"{doc.category}_{doc.subcategory}_{i}\" if doc.subcategory else f\"{doc.category}_{i}\"\n+                    \n+                    # Clean metadata - ensure all values are strings, numbers, or booleans\n+                    clean_metadata = {\n+                        \"title\": str(doc.title) if doc.title else \"Unknown\",\n+                        \"category\": str(doc.category) if doc.category else \"general\",\n+                        \"subcategory\": str(doc.subcategory) if doc.subcategory else \"general\",\n+                        \"chunk_index\": i,\n+                        \"total_chunks\": len(code_chunks),\n+                        \"source_url\": str(doc.source_url) if doc.source_url else \"unknown\",\n+                        \"chunk_type\": str(code_chunk.chunk_type.value),\n+                        \"language\": str(code_chunk.language),\n+                        \"importance\": str(code_chunk.importance),\n+                        \"start_line\": code_chunk.start_line,\n+                        \"end_line\": code_chunk.end_line,\n+                        \"code_aware\": True\n+                    }\n+                    \n+                    # Add metadata from code chunk\n+                    for key, value in code_chunk.metadata.items():\n+                        if value is None:\n+                            clean_metadata[key] = \"unknown\"\n+                        elif isinstance(value, (str, int, float, bool)):\n+                            clean_metadata[key] = value\n+                        else:\n+                            clean_metadata[key] = str(value)\n+                    \n+                    # Add other metadata from doc, ensuring all values are properly converted\n+                    for key, value in doc.metadata.items():\n+                        if key not in clean_metadata:\n+                            if value is None:\n+                                clean_metadata[key] = \"unknown\"\n+                            elif isinstance(value, (str, int, float, bool)):\n+                                clean_metadata[key] = value\n+                            else:\n+                                clean_metadata[key] = str(value)\n+                    \n+                    chunked_docs.append({\n+                        \"id\": chunk_id,\n+                        \"content\": code_chunk.content,\n+                        \"metadata\": clean_metadata\n+                    })\n+                \n+                logger.info(f\"üìù Code-aware chunking: {len(code_chunks)} chunks from {doc.file_path}\")\n+                return chunked_docs\n+                \n+            except Exception as e:\n+                logger.warning(f\"Code-aware chunking failed for {doc.file_path}: {e}\")\n+                # Fall back to regular chunking\n+        \n+        # Fallback to regular text splitting\n@@ -437 +501,0 @@ class AstraTradeRAG:\n-        chunked_docs = []\n@@ -448 +512,2 @@ class AstraTradeRAG:\n-                \"source_url\": str(doc.source_url) if doc.source_url else \"unknown\"\n+                \"source_url\": str(doc.source_url) if doc.source_url else \"unknown\",\n+                \"code_aware\": False\ndiff --git a/knowledge_base/backend/test_code_aware_chunker.py b/knowledge_base/backend/test_code_aware_chunker.py\nnew file mode 100644\nindex 0000000..907f1ed\n--- /dev/null\n+++ b/knowledge_base/backend/test_code_aware_chunker.py\n@@ -0,0 +1,203 @@\n+#!/usr/bin/env python3\n+\"\"\"\n+Test script for CodeAwareChunker\n+\"\"\"\n+\n+import os\n+import sys\n+from pathlib import Path\n+from config import RAG_CONFIG\n+from code_aware_chunker import CodeAwareChunker\n+\n+def test_python_chunking():\n+    \"\"\"Test Python file chunking\"\"\"\n+    python_code = '''#!/usr/bin/env python3\n+\"\"\"\n+Test Python file for chunking\n+\"\"\"\n+\n+import os\n+import sys\n+from typing import List, Dict\n+\n+def hello_world():\n+    \"\"\"Simple hello world function\"\"\"\n+    print(\"Hello, World!\")\n+    return \"Hello, World!\"\n+\n+class TestClass:\n+    \"\"\"Test class for chunking\"\"\"\n+    \n+    def __init__(self, name: str):\n+        self.name = name\n+    \n+    def greet(self):\n+        \"\"\"Greet method\"\"\"\n+        return f\"Hello from {self.name}!\"\n+    \n+    def calculate(self, a: int, b: int) -> int:\n+        \"\"\"Calculate sum\"\"\"\n+        return a + b\n+\n+async def async_function():\n+    \"\"\"Async function example\"\"\"\n+    await asyncio.sleep(1)\n+    return \"async result\"\n+'''\n+    \n+    chunker = CodeAwareChunker(RAG_CONFIG)\n+    chunks = chunker.chunk_file(\"example.py\", python_code)\n+    \n+    print(f\"Python chunking test:\")\n+    print(f\"Generated {len(chunks)} chunks\")\n+    \n+    for i, chunk in enumerate(chunks):\n+        print(f\"  Chunk {i+1}: {chunk.chunk_type.value} - {chunk.metadata.get('description', 'No description')}\")\n+        print(f\"    Lines {chunk.start_line}-{chunk.end_line}\")\n+        print(f\"    Size: {len(chunk.content)} chars\")\n+        print(f\"    Importance: {chunk.importance}\")\n+        print()\n+    \n+    # Verify we have expected chunks\n+    chunk_types = [chunk.chunk_type.value for chunk in chunks]\n+    print(f\"Chunk types: {chunk_types}\")\n+    \n+    # Should have class and functions (imports are not captured since they're not in the code)\n+    assert \"class\" in chunk_types, \"Should have class chunk\"\n+    assert \"function\" in chunk_types, \"Should have function chunks\"\n+    assert \"documentation\" in chunk_types, \"Should have documentation chunk\"\n+    \n+    print(\"‚úÖ Python chunking test passed!\")\n+\n+def test_markdown_chunking():\n+    \"\"\"Test Markdown file chunking\"\"\"\n+    markdown_content = '''# Main Title\n+\n+This is the introduction section.\n+\n+## Section 1: Getting Started\n+\n+This section covers getting started with the system.\n+\n+### Subsection 1.1: Installation\n+\n+Step-by-step installation guide.\n+\n+### Subsection 1.2: Configuration\n+\n+Configuration details here.\n+\n+## Section 2: Reference\n+\n+Documentation goes here.\n+\n+### Command Line\n+\n+CLI usage.\n+\n+### Configuration Files\n+\n+Config file details.\n+\n+## Conclusion\n+\n+Final thoughts and summary.\n+'''\n+    \n+    chunker = CodeAwareChunker(RAG_CONFIG)\n+    chunks = chunker.chunk_file(\"example.md\", markdown_content)\n+    \n+    print(f\"Markdown chunking test:\")\n+    print(f\"Generated {len(chunks)} chunks\")\n+    \n+    for i, chunk in enumerate(chunks):\n+        print(f\"  Chunk {i+1}: {chunk.metadata.get('section_title', 'No title')}\")\n+        print(f\"    Level: {chunk.metadata.get('header_level', 'N/A')}\")\n+        print(f\"    Lines {chunk.start_line}-{chunk.end_line}\")\n+        print(f\"    Size: {len(chunk.content)} chars\")\n+        print(f\"    Importance: {chunk.importance}\")\n+        print()\n+    \n+    # Verify we have expected sections\n+    section_titles = [chunk.metadata.get('section_title', '') for chunk in chunks]\n+    print(f\"Section titles: {section_titles}\")\n+    \n+    # Should have main sections\n+    assert \"Main Title\" in section_titles, \"Should have main title\"\n+    assert \"Section 1: Getting Started\" in section_titles, \"Should have section 1\"\n+    assert \"Section 2: Reference\" in section_titles, \"Should have section 2\"\n+    \n+    print(\"‚úÖ Markdown chunking test passed!\")\n+\n+def test_integration():\n+    \"\"\"Test integration with RAG system\"\"\"\n+    try:\n+        from rag_system import AstraTradeRAG\n+        from models import ProcessedDocument\n+        \n+        # Create a test document\n+        test_doc = ProcessedDocument(\n+            content='''# Test Document\n+\n+This is a test document.\n+\n+## Section 1\n+\n+Content for section 1.\n+\n+```python\n+def example_function():\n+    return \"hello\"\n+```\n+\n+## Section 2\n+\n+Content for section 2.\n+''',\n+            title=\"Test Document\",\n+            category=\"test\",\n+            subcategory=\"example\",\n+            metadata={\"test\": True},\n+            source_url=\"http://example.com\",\n+            file_path=\"example.md\"\n+        )\n+        \n+        # Test the chunk_document method\n+        rag = AstraTradeRAG()\n+        chunks = rag._chunk_document(test_doc)\n+        \n+        print(f\"Integration test:\")\n+        print(f\"Generated {len(chunks)} chunks\")\n+        \n+        for i, chunk in enumerate(chunks):\n+            print(f\"  Chunk {i+1}: {chunk['metadata'].get('chunk_type', 'unknown')}\")\n+            print(f\"    Code aware: {chunk['metadata'].get('code_aware', False)}\")\n+            print(f\"    Size: {len(chunk['content'])} chars\")\n+            print()\n+        \n+        # Verify code-aware chunking was used\n+        code_aware_chunks = [chunk for chunk in chunks if chunk['metadata'].get('code_aware', False)]\n+        print(f\"Code-aware chunks: {len(code_aware_chunks)}/{len(chunks)}\")\n+        \n+        if code_aware_chunks:\n+            print(\"‚úÖ Integration test passed!\")\n+        else:\n+            print(\"‚ö†Ô∏è  Integration test: code-aware chunking not used\")\n+        \n+    except Exception as e:\n+        print(f\"‚ùå Integration test failed: {e}\")\n+\n+if __name__ == \"__main__\":\n+    print(\"Testing CodeAwareChunker...\")\n+    print(\"=\" * 50)\n+    \n+    test_python_chunking()\n+    print()\n+    \n+    test_markdown_chunking()\n+    print()\n+    \n+    test_integration()\n+    print()\n+    \n+    print(\"All tests completed!\")\n\\ No newline at end of file\ndiff --git a/knowledge_base/backend/test_markdown_simple.py b/knowledge_base/backend/test_markdown_simple.py\nnew file mode 100644\nindex 0000000..38a8e56\n--- /dev/null\n+++ b/knowledge_base/backend/test_markdown_simple.py\n@@ -0,0 +1,51 @@\n+#!/usr/bin/env python3\n+\"\"\"\n+Simple test for Markdown chunking\n+\"\"\"\n+\n+from config import RAG_CONFIG\n+from code_aware_chunker import CodeAwareChunker\n+\n+def test_markdown_direct():\n+    \"\"\"Test Markdown chunking directly\"\"\"\n+    markdown_content = '''# Main Title\n+\n+This is the introduction section.\n+\n+## Section 1: Getting Started\n+\n+This section covers getting started with the system.\n+\n+### Subsection 1.1: Installation\n+\n+Step-by-step installation guide.\n+\n+## Section 2: Reference\n+\n+Documentation goes here.\n+\n+### Command Line\n+\n+CLI usage.\n+\n+## Conclusion\n+\n+Final thoughts and summary.\n+'''\n+    \n+    chunker = CodeAwareChunker(RAG_CONFIG)\n+    chunks = chunker._chunk_markdown(markdown_content, \"example.md\")\n+    \n+    print(f\"Markdown chunking test:\")\n+    print(f\"Generated {len(chunks)} chunks\")\n+    \n+    for i, chunk in enumerate(chunks):\n+        print(f\"  Chunk {i+1}: {chunk.metadata.get('section_title', 'No title')}\")\n+        print(f\"    Level: {chunk.metadata.get('header_level', 'N/A')}\")\n+        print(f\"    Lines {chunk.start_line}-{chunk.end_line}\")\n+        print(f\"    Size: {len(chunk.content)} chars\")\n+        print(f\"    First 50 chars: {chunk.content[:50]}\")\n+        print()\n+\n+if __name__ == \"__main__\":\n+    test_markdown_direct()\n\\ No newline at end of file\ndiff --git a/knowledge_base/backend/test_real_world.py b/knowledge_base/backend/test_real_world.py\nnew file mode 100644\nindex 0000000..7e1c61f\n--- /dev/null\n+++ b/knowledge_base/backend/test_real_world.py\n@@ -0,0 +1,184 @@\n+#!/usr/bin/env python3\n+\"\"\"\n+Real-world integration test for code-aware chunker\n+\"\"\"\n+\n+import json\n+import requests\n+from pathlib import Path\n+\n+def test_search_function():\n+    \"\"\"Test searching for a specific function\"\"\"\n+    url = \"http://localhost:8000/search\"\n+    headers = {\"Content-Type\": \"application/json\"}\n+    \n+    # Search for a function that should exist in the codebase\n+    data = {\n+        \"query\": \"search_for_claude\",\n+        \"max_results\": 3,\n+        \"min_similarity\": 0.25\n+    }\n+    \n+    try:\n+        response = requests.post(url, json=data, headers=headers)\n+        if response.status_code == 200:\n+            results = response.json()\n+            print(f\"Search results for 'search_for_claude':\")\n+            print(f\"Found {results['total_results']} results\")\n+            \n+            for i, result in enumerate(results['results']):\n+                print(f\"  Result {i+1}:\")\n+                print(f\"    Code aware: {result.get('code_aware', 'N/A')}\")\n+                print(f\"    Chunk type: {result.get('chunk_type', 'N/A')}\")\n+                print(f\"    Language: {result.get('language', 'N/A')}\")\n+                print(f\"    Relevance: {result.get('relevance', 'N/A')}\")\n+                print(f\"    First 100 chars: {result.get('content', '')[:100]}\")\n+                print()\n+            \n+            # Check if we found function chunks\n+            function_chunks = [r for r in results['results'] if r.get('chunk_type') == 'function']\n+            if function_chunks:\n+                print(\"‚úÖ Found function chunks from code-aware chunking!\")\n+                return True\n+            else:\n+                print(\"‚ö†Ô∏è  No function chunks found\")\n+                return False\n+        else:\n+            print(f\"‚ùå Search request failed: {response.status_code}\")\n+            return False\n+            \n+    except Exception as e:\n+        print(f\"‚ùå Search test failed: {e}\")\n+        return False\n+\n+def test_search_python_class():\n+    \"\"\"Test searching for a Python class\"\"\"\n+    url = \"http://localhost:8000/search\"\n+    headers = {\"Content-Type\": \"application/json\"}\n+    \n+    # Search for a class that should exist\n+    data = {\n+        \"query\": \"CodeAwareChunker\",\n+        \"max_results\": 3,\n+        \"min_similarity\": 0.25\n+    }\n+    \n+    try:\n+        response = requests.post(url, json=data, headers=headers)\n+        if response.status_code == 200:\n+            results = response.json()\n+            print(f\"Search results for 'CodeAwareChunker':\")\n+            print(f\"Found {results['total_results']} results\")\n+            \n+            for i, result in enumerate(results['results']):\n+                print(f\"  Result {i+1}:\")\n+                print(f\"    Code aware: {result.get('code_aware', 'N/A')}\")\n+                print(f\"    Chunk type: {result.get('chunk_type', 'N/A')}\")\n+                print(f\"    Language: {result.get('language', 'N/A')}\")\n+                print(f\"    First 100 chars: {result.get('content', '')[:100]}\")\n+                print()\n+            \n+            # Check if we found class chunks\n+            class_chunks = [r for r in results['results'] if r.get('chunk_type') == 'class']\n+            if class_chunks:\n+                print(\"‚úÖ Found class chunks from code-aware chunking!\")\n+                return True\n+            else:\n+                print(\"‚ö†Ô∏è  No class chunks found\")\n+                return False\n+        else:\n+            print(f\"‚ùå Search request failed: {response.status_code}\")\n+            return False\n+            \n+    except Exception as e:\n+        print(f\"‚ùå Search test failed: {e}\")\n+        return False\n+\n+def test_search_markdown_section():\n+    \"\"\"Test searching for markdown sections\"\"\"\n+    url = \"http://localhost:8000/search\"\n+    headers = {\"Content-Type\": \"application/json\"}\n+    \n+    # Search for markdown sections\n+    data = {\n+        \"query\": \"Getting Started\",\n+        \"max_results\": 3,\n+        \"min_similarity\": 0.25\n+    }\n+    \n+    try:\n+        response = requests.post(url, json=data, headers=headers)\n+        if response.status_code == 200:\n+            results = response.json()\n+            print(f\"Search results for 'Getting Started':\")\n+            print(f\"Found {results['total_results']} results\")\n+            \n+            for i, result in enumerate(results['results']):\n+                print(f\"  Result {i+1}:\")\n+                print(f\"    Code aware: {result.get('code_aware', 'N/A')}\")\n+                print(f\"    Chunk type: {result.get('chunk_type', 'N/A')}\")\n+                print(f\"    Language: {result.get('language', 'N/A')}\")\n+                print(f\"    Section title: {result.get('section_title', 'N/A')}\")\n+                print(f\"    First 100 chars: {result.get('content', '')[:100]}\")\n+                print()\n+            \n+            # Check if we found documentation chunks\n+            doc_chunks = [r for r in results['results'] if r.get('chunk_type') == 'documentation']\n+            if doc_chunks:\n+                print(\"‚úÖ Found documentation chunks from code-aware chunking!\")\n+                return True\n+            else:\n+                print(\"‚ö†Ô∏è  No documentation chunks found\")\n+                return False\n+        else:\n+            print(f\"‚ùå Search request failed: {response.status_code}\")\n+            return False\n+            \n+    except Exception as e:\n+        print(f\"‚ùå Search test failed: {e}\")\n+        return False\n+\n+def test_stats():\n+    \"\"\"Test getting stats to see if code-aware chunking is working\"\"\"\n+    url = \"http://localhost:8000/stats\"\n+    \n+    try:\n+        response = requests.get(url)\n+        if response.status_code == 200:\n+            stats = response.json()\n+            print(f\"Knowledge base stats:\")\n+            print(f\"  Total documents: {stats['total_documents']}\")\n+            print(f\"  Categories: {stats['categories']}\")\n+            print(f\"  Embedding model: {stats['embedding_model']}\")\n+            print(f\"  Last updated: {stats['last_updated']}\")\n+            print()\n+            return True\n+        else:\n+            print(f\"‚ùå Stats request failed: {response.status_code}\")\n+            return False\n+            \n+    except Exception as e:\n+        print(f\"‚ùå Stats test failed: {e}\")\n+        return False\n+\n+if __name__ == \"__main__\":\n+    print(\"Testing real-world code-aware chunking integration...\")\n+    print(\"=\" * 60)\n+    \n+    # Test basic stats\n+    if test_stats():\n+        print()\n+        \n+        # Test function search\n+        if test_search_function():\n+            print()\n+        \n+        # Test class search\n+        if test_search_python_class():\n+            print()\n+        \n+        # Test markdown section search\n+        if test_search_markdown_section():\n+            print()\n+    \n+    print(\"Real-world integration test completed!\")\n\\ No newline at end of file",
  "metadata": {
    "type": "commit",
    "special_code": "2dd5efe796607de52644e1bead06183427c7fb30",
    "author": "Peter",
    "date": "2025-07-11 19:29:12 +0700"
  }
}